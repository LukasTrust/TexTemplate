@article{Kerbl18RVC,
	title = {Revisiting The Vertex Cache: Understanding and Optimizing Vertex Processing on the modern {GPU}},
	volume = {1},
	issn = {2577-6193},
	HIDDEN_url = {https://dl.acm.org/doi/10.1145/3233302},
	HIDDEN_doi = {10.1145/3233302},
	shorttitle = {Revisiting The Vertex Cache},
	pages = {1--16},
	number = {2},
	journaltitle = {Proceedings of the {ACM} on Computer Graphics and Interactive Techniques},
	shortjournal = {Proc. {ACM} Comput. Graph. Interact. Tech.},
	author = {Kerbl, Bernhard and Kenzel, Michael and Ivanchenko, Elena and Schmalstieg, Dieter and Steinberger, Markus},
	urldate = {2023-08-03},
	year = {2018},
	langid = {english},	
}

@inproceedings{zafar2010gpu,
  title={{GPU} random numbers via the tiny encryption algorithm},
  author={Zafar, Fahad and Olano, Marc and Curtis, Aaron},
  booktitle={Proceedings of the Conference on High Performance Graphics},
  pages={133--141},
  year={2010}
}

@manual{Khronos23VS,
 organization = {Khronos Group},
 title = "Vulkan 1.3.260 - A Specification (with all registered Vulkan extensions)",    
 year =  2023,
 month =  02,
 day =  16,
}

@manual{DirectXSpecs,
 organization = {Microsoft},
 title = "DirectX-Specs",
 url = "https://microsoft.github.io/DirectX-Specs/",
 year = 2023,
}

@manual{DirectXReference,
 organization = {Microsoft},
 title = "Direct3D 12 Graphics",
 url = "https://learn.microsoft.com/en-us/windows/win32/api/_direct3d12/",
 year = 2023,
}

@manual{Kubisch18Introduction,
 author = {Kubisch, C.},
 title = {Introduction to {Turing} Mesh Shaders},    
 year =  2018,
 month = 09,    
 day =  17,   
 url = "https://developer.nvidia.com/blog/introduction-turing-mesh-shaders/",
}

@manual{Mihut21Advanced,
 author = {Mihut, A. and Kubisch, C. and Kraemer, M.},
 title = {Advanced API Performance: Mesh Shaders},    
 year =  2021,
 month = 10,    
 day =  25,   
 url = "https://developer.nvidia.com/blog/advanced-api-performance-mesh-shaders/",
}

@manual{HLSLfirstbithigh,
 organization = "Microsoft",
 title = {{High-level shader language (HLSL)}},
 year = 2020,
 month = 08,
 day = 19,
 url = {https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl},
}

@manual{GLSLfindMSB,
 organization = "Khronos Group",
 title = {The {OpenGL} Shading Language, Version 4.60.7},
 year = 2019,
 month = 06,
 day = 10,
}

@manual{AMDCLZ,
 organization = "AMD",
 title = "``RDNA3`` Instruction Set Architecture",
 year = 2023,
 month = 02,
 day = 20,
 URL = "https://www.amd.com/system/files/TechDocs/rdna3-shader-instruction-set-architecture-feb-2023_0.pdf"
}

@inproceedings{Evans96OTS,
	location = {San Francisco, {CA}, {USA}},
	title = {Optimizing triangle strips for fast rendering},
	isbn = {978-0-89791-864-0},
	HIDDEN_doi = {10.1109/VISUAL.1996.568125},
	eventtitle = {Seventh Annual {IEEE} Visualization '96},
	pages = {319--326},
	booktitle = {Proceedings of Seventh Annual {IEEE} Visualization '96},
	publisher = {{ACM}},
	author = {Evans, F. and Skiena, S. and Varshney, A.},	
	year = {1996},
	langid = {english},	
}

@article{Velho99HGT,
	author = {Velho, Luiz and de Figueiredo, Luiz Henrique and Gomes, Jonas},	
	title = {Hierarchical generalized triangle strips},
	volume = {15},
	year = {1999},		
	pages = {21--35},
	number = {1},
	journal = {The Visual Computer},
}

@article{Meyer12DPD,
author = {Meyer, Quirin and Keinert, Benjamin and Sußner, Gerd and Stamminger, Marc},
title = {Data-Parallel Decompression of Triangle Mesh Topology},
journal = {Computer Graphics Forum},
volume = {31},
number = {8},
pages = {2541-2553},
year = {2012}
}


@article{Arkin96HTF,
	title = {Hamiltonian triangulations for fast rendering},
	volume = {12},
	issn = {1432-2315},
	HIDDEN_url = {https://doi.org/10.1007/BF01782475},
	HIDDEN_doi = {10.1007/BF01782475},	
	pages = {429--444},
	number = {9},
	journal = {The Visual Computer},	
	author = {Arkin, Esther M. and Held, Martin and Mitchell, Joseph S. B. and Skiena, Steven S.},
	year = {1996},	
}

@inproceedings{Stewart01TTS,
  title={Tunneling for triangle strips in continuous level-of-detail meshes},
  author={Stewart, A James},
  booktitle={Graphics interface},
  volume={2001},
  pages={91--100},
  year={2001}
}

@article{Vanecek07CTS,
title = {Comparison of triangle strips algorithms},
journal = {Computers and Graphics},
volume = {31},
number = {1},
pages = {100-118},
year = {2007},
issn = {0097-8493},
author = {Petr Vaněček and Ivana Kolingerová},
}

@techreport{Kilgard08MOU,
title = {{Modern OpenGL usage: Using vertex buffer objects well}},
year = {2008},
institution = {NVIDIA Corporation},
author = {Mark Kilgard},
}

@inproceedings{Estkowski02ODP,
author = {Estkowski, Regina and Mitchell, Joseph S. B. and Xiang, Xinyu},
title = {Optimal Decomposition of Polygonal Models into Triangle Strips},
year = {2002},
isbn = {1581135041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the Eighteenth Annual Symposium on Computational Geometry},
pages = {254–263},
numpages = {10},
keywords = {NP-completeness, tristrips, rendering, branch and bound, triangle strips, integer programming},
location = {Barcelona, Spain},
series = {SCG '02}
}

@software{Gurobi23GOL,
  author = {{Gurobi Optimization, LLC}},
  title = {{Gurobi Optimizer Reference Manual}},
  year = {2023},
  url = {https://www.gurobi.com}
}  

@unpublished{Cohen19SGP,
  TITLE = {{Several Graph problems and their Linear Program formulations}},
  AUTHOR = {Cohen, Nathann},
  URL = {https://hal.inria.fr/inria-00504914},
  NOTE = {working paper or preprint},
  YEAR = {2019},
  MONTH = Jan,
  PDF = {https://hal.inria.fr/inria-00504914v2/file/LP_formulations.pdf},
  HAL_ID = {inria-00504914},
  HAL_VERSION = {v2},
}

@inproceedings{karis2021nanite,
  title={A Deep Dive into Nanite Virtualized Geometry},
  author={Karis, Brian and Stubbe, Rune and Wihlidal, Graham},
  booktitle={ACM SIGGRAPH},
  year={2021}
}

@software{MeshOptimizer,
  author = {Kapoulkine, Arseny},
  title = {{meshoptimizer}},
  year = 2023,
  url = "https://github.com/zeux/meshoptimizer"
}

@manual{DirectXSamples,
 organization = {Microsoft},
  title = {{DirectX-Graphics-Samples}},
  year = 2023,
  url = "https://github.com/microsoft/DirectX-Graphics-Samples"
}

@techreport{SCIP,
  author = {Ksenia Bestuzheva and Mathieu Besan{\c{c}}on and Wei-Kun Chen and Antonia Chmiela and Tim Donkiewicz and Jasper van Doornmalen and Leon Eifler and Oliver Gaul and Gerald Gamrath and Ambros Gleixner and Leona Gottwald and Christoph Graczyk and Katrin Halbig and Alexander Hoen and Christopher Hojny and Rolf van der Hulst and Thorsten Koch and Marco L{\"u}bbecke and Stephen J. Maher and Frederic Matter and Erik M{\"u}hmer and Benjamin M{\"u}ller and Marc E. Pfetsch and Daniel Rehfeldt and Steffan Schlein and Franziska Schl{\"o}sser and Felipe Serrano and Yuji Shinano and Boro Sofranac and Mark Turner and Stefan Vigerske and Fabian Wegscheider and Philipp Wellner and Dieter Weninger and Jakob Witzig},
  title = {{The SCIP Optimization Suite 8.0}},
  type = {Technical Report},
  institution = {Optimization Online},
  month = {December},
  year = {2021},
  url = {http://www.optimization-online.org/DB_HTML/2021/12/8728.html}
}

@inproceedings{porcu2006partitioning,
  title={{Partitioning Meshes into Strips using the Enhanced Tunnelling Algorithm (ETA)}},
  author={Porcu, Massimiliano B and Scateni, Riccardo},
  booktitle={VRIPHYS},
  pages={61--70},
  year={2006}
}

@misc{thrust2023,
  author={Nvidia}, 
  title={{Thrust}: The {C++} Parallel Algorithms Library},
  url = {https://github.com/NVIDIA/thrust},
  year={2023}
}

@misc{rocThrust2023,
  author={AMD}, 
  title={{rocThrust}},
  url = {https://github.com/ROCmSoftwarePlatform/rocThrust},
  year={2023}
}

@ARTICLE{Kwan18PVD,
  author={K. C. {Kwan} and X. {Xu} and L. {Wan} and T. {Wong} and W. {Pang}},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Packing Vertex Data into Hardware-Decompressible Textures}, 
  year={2018},
  volume={24},
  number={5},
  HIDDEN_pages={1705-1716},
  HIDDEN_doi={10.1109/TVCG.2017.2695182}
}

@inproceedings{Olano11VBR,
    author = {Olano, Marc and Baker, Dan and Griffin, Wesley and Barczak, Joshua},
    title = {Variable Bit Rate {GPU} Texture Decompression},
    year = {2011},
    publisher = {Eurographics Association},
    HIDDEN_address = {Goslar, DEU},
    HIDDEN_url = {https://doi.org/10.1111/j.1467-8659.2011.01989.x},
    HIDDEN_doi = {10.1111/j.1467-8659.2011.01989.x},
    booktitle = {Proceedings of the Twenty-Second Eurographics Conference on Rendering},
    HIDDEN_pages = {1299–1308},
    HIDDEN_numpages = {10},
    HIDDEN_location = {Prague, Czech Republic},
    HIDDEN_series = {EGSR '11}
}

@online{BinomialLLC2020Crunch,
    author = {{Binomial LLC}},
    title = {Advanced DXTn texture compression library},
    year = {2020},
    url = {https://github.com/BinomialLLC/crunch},
    urldate = {2021-02-10}
}

@online{BinomialLLC21BUS,
    author = {{Binomial LLC}},
    title = {Basis Universal Supercompressed GPU Texture Codec},
    year = {2021},
    url = {https://github.com/BinomialLLC/basis_universal},
    urldate = {2021-02-10}
}
@online{Kubisch20MSP,
    author={Kubisch, Christoph},
    title={Using Mesh Shaders for Professional Graphics},
    year={2020},
    url={https://developer.nvidia.com/blog/using-mesh-shaders-for-professional-graphics/},
    urldate={2021-02-10}
}

@online{Sakharnykh20ODT,
    author={Sakharnykh, Nikolay and LaSalle, Dominique  and Karsin, Ben},
    title={Optimizing Data Transfer Using Lossless Compression with NVIDIA nvcomp},
    url={https://developer.nvidia.com/blog/optimizing-data-transfer-using-lossless-compression-with-nvcomp/},
    year={2020}
}

@manual{Collet19LZ4,
    author={Collet, Yann},
    title={LZ4 Block Format Description},
    year={2019},
}

@manual{Imagination20IBS,
    organization="Imagination Technologies",
    title="IMG B-Series features IMGIC framebuffer compression technology - the ultimate low-bandwidth GPU IP solution",
    year="2020"
}

@online{Brennan16GMO,
    author="Brennan, Chris",
    title="Getting the most out of delta color compression", 
    url="https://gpuopen.com/learn/dcc-overview/",
    urldate="2021-02-12",
    year="2016"
}

@online{Hugosson13MVV,
    author="Hugosson, Ola",
    title="Mali-V500 video processor: reducing memory bandwidth with AFBC",
    url="https://community.arm.com/developer/tools-software/graphics/b/blog/posts/mali-v500-video-processor-reducing-memory-bandwidth-with-afbc",
    urldate="2021-02-12",
    year="2016"
}

@patent{McAllister14LFB,
    title="Lossless frame buffer color compression",
    author="McAllister, David K. and Joly, Alexandre and Tong, Peter",
    number="United States Patent 8670613",
    year="2014",
}

@manual{Garrad19KDF,
    author        = {Garrad, Andrew},
    organization  = {The Khronos Group Inc.},
    title         = {Khronos Data Format Specification v1.3.1},
    year          = {2019},
}  

@article{Rousseau20UUV,
  author =       {Sylvain Rousseau and Tamy Boubekeur}, 
  title =        {Unorganized Unit Vectors Sets Quantization},
  year =         {2020},
  HIDDEN_month =        {December},
  HIDDEN_day =          4,
  journal =      {Journal of Computer Graphics Techniques (JCGT)},
  volume =       9,
  number =       3,
  HIDDEN_pages =        {92--107},
  HIDDEN_url =          {http://jcgt.org/published/0009/03/05/},
  HIDDEN_issn =         {2331-7418}
}          

@article{Keinert15SFM,
    author = {Keinert, Benjamin and Innmann, Matthias and S\"{a}nger, Michael and Stamminger, Marc},
    title = {Spherical Fibonacci Mapping},
    year = {2015},
    issue_date = {November 2015},
    publisher = {Association for Computing Machinery},
    HIDDEN_address = {New York, NY, USA},
    volume = {34},
    number = {6},
    HIDDEN_issn = {0730-0301},
    HIDDEN_url = {https://doi.org/10.1145/2816795.2818131},
    HIDDEN_doi = {10.1145/2816795.2818131},
    journal = {ACM Trans. Graph.},
    month = oct,
    HIDDEN_articleno = {193},
    HIDDEN_numpages = {7},
}

@article{Cigolle2014SER,
   author  = {Zina H. Cigolle and Sam Donow and Daniel Evangelakos and Michael Mara and Morgan McGuire and Quirin Meyer},
   title   = {A Survey of Efficient Representations for Independent Unit Vectors},
   year    = {2014},
   month   = {April},
   day     = {17},
   journal = {Journal of Computer Graphics Techniques (JCGT)},
   volume  = {3},
   number  = {2},
   HIDDEN_pages   = {1--30},
   HIDDEN_url     = {http://jcgt.org/published/0003/02/01/},
   HIDDEN_issn    = {2331-7418}
}          

@article{Jakob17PAC,
    author = {Jakob, Johannes and Buchenau, Christoph and Guthe, Michael},
    title = {A Parallel Approach to Compression and Decompression of Triangle Meshes Using the {GPU}},
    year = {2017},
    issue_date = {August 2017},
    publisher = {The Eurographs Association & John Wiley & Sons, Ltd.},
    HIDDEN_address = {Chichester, GBR},
    volume = {36},
    number = {5},
    HIDDEN_issn = {0167-7055},
    HIDDEN_url = {https://doi.org/10.1111/cgf.13246},
    HIDDEN_doi = {10.1111/cgf.13246},
    journal = {Comput. Graph. Forum},
    month = aug,
    HIDDEN_pages = {71-80},
    HIDDEN_numpages = {10},
}

@inproceedings{Gumhold98CBM,
    author = {Gumhold, Stefan and Stra\ss{}er, Wolfgang},
    title = {Real Time Compression of Triangle Mesh Connectivity},
    year = {1998},
    HIDDEN_isbn = {0897919998},
    publisher = {Association for Computing Machinery},
    HIDDEN_address = {New York, NY, USA},
    HIDDEN_url = {https://doi.org/10.1145/280814.280836},
    HIDDEN_doi = {10.1145/280814.280836},
    booktitle = {Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques},
    HIDDEN_pages = {133–140},
    HIDDEN_numpages = {8},
    HIDDEN_series = {SIGGRAPH '98}
}


@article{Tutte62CPT, 
    title={A Census of Planar Triangulations}, 
    volume={14}, 
    HIDDEN_DOI={10.4153/CJM-1962-002-9}, 
    journal={Canadian Journal of Mathematics}, 
    publisher={Cambridge University Press}, 
    author={Tutte, William Thomas}, 
    year={1962}, 
    pages={21–38}
    }

    @inproceedings{Purnomo05HCV,
    author = {Purnomo, Budirijanto and Bilodeau, Jonathan and Cohen, Jonathan D. and Kumar, Subodh},
    title = {Hardware-Compatible Vertex Compression Using Quantization and Simplification},
    year = {2005},
    HIDDEN_isbn = {1595930868},
    publisher = {Association for Computing Machinery},
    HIDDEN_address = {New York, NY, USA},
    HIDDEN_url = {https://doi.org/10.1145/1071866.1071876},
    HIDDEN_doi = {10.1145/1071866.1071876},
    HIDDEN_pages = {53-61},
    HIDDEN_numpages = {9},
    HIDDEN_location = {Los Angeles, California},
    series = {HWWS '05}
}

@inproceedings {Meyer11ALP,
    booktitle = {Vision, Modeling, and Visualization (2011)},
    HIDDEN_editor = {Peter Eisert and Joachim Hornegger and Konrad Polthier},
    title = {Adaptive Level-of-Precision for {GPU}-Rendering},
    author = {Meyer, Quirin and Su\ss{}ner, Gerd and Greiner, G\"unther and Stamminger, Marc},
    year = {2011},
    publisher = {The Eurographics Association},
    HIDDEN_ISBN = {978-3-905673-85-2},
    HIDDEN_DOI = {10.2312/PE/VMV/VMV11/169-176}
}

@inproceedings{Frey11SSD,
    author = {Frey, Ivo Zoltan and Herzeg, Ivo},
    title = {Spherical Skinning with Dual Quaternions and QTangents},
    year = {2011},
    HIDDEN_isbn = {9781450309745},
    publisher = {Association for Computing Machinery},
    HIDDEN_address = {New York, NY, USA},
    HIDDEN_url = {https://doi.org/10.1145/2037826.2037841},
    HIDDEN_doi = {10.1145/2037826.2037841},
    booktitle = {ACM SIGGRAPH 2011 Talks},
    HIDDEN_articleno = {11},
    HIDDEN_numpages = {1},
    HIDDEN_location = {Vancouver, British Columbia, Canada},
    series = {SIGGRAPH '11}
}

@article{Peng05T3M,
    title = "{Technologies for 3D mesh compression: A survey}",
    journal = "Journal of Visual Communication and Image Representation",
    volume = "16",
    number = "6",
    HIDDEN_pages = "688 - 733",
    year = "2005",
    HIDDEN_issn = "1047-3203",
    HIDDEN_doi = "https://doi.org/10.1016/j.jvcir.2005.03.001",
    HIDDEN_url = "http://www.sciencedirect.com/science/article/pii/S1047320305000295",
    author = "Jingliang Peng and Chang-Su Kim and C.-C. {Jay Kuo}",
    HIDDEN_keywords = "3D mesh compression, Single-rate mesh coding, Progressive mesh coding, MPEG-4",
}

@article{Maglo153MC,
    author = {Maglo, Adrien and Lavou\'{e}, Guillaume and Dupont, Florent and Hudelot, C\'{e}line},
    title = {3D Mesh Compression: Survey, Comparisons, and Emerging Trends},
    year = {2015},    
    journal = {ACM Comput. Surv.},
    publisher = {Association for Computing Machinery},
    HIDDEN_address = {New York, NY, USA},
    volume = {47},
    number = {3},
    HIDDEN_issn = {0360-0300},
    HIDDEN_url = {https://doi.org/10.1145/2693443},
    HIDDEN_doi = {10.1145/2693443},
    HIDDEN_month = feb,
    HIDDEN_articleno = {44},
    HIDDEN_numpages = {41},
    HIDDEN_keywords = {compression, progressive, random accessible, 3D mesh, single rate, dynamic}
}

@InProceedings{Alliez03RAC,
    author="Alliez, Pierre and Gotsman, Craig",
    HIDDEN_editor="Dodgson, Neil A. and Floater, Michael S. and Sabin, Malcolm A.",
    title="Recent Advances in Compression of {3D} Meshes",
    booktitle="Advances in Multiresolution for Geometric Modelling",
    year="2003",
    publisher="Springer Berlin Heidelberg",
    HIDDEN_address="Berlin, Heidelberg",
    HIDDEN_pages="3--26",
    HIDDEN_isbn="978-3-540-26808-6"
}

@article{Lee10C3M,
    author = {Lee, Jongseok and Choe, Sungyul and Lee, Seungyong},
    year = {2010},
    month = {09},
    HIDDEN_pages = {207-224},
    title = {{Compression of 3D Mesh Geometry and Vertex Attributes for Mobile Graphics}},
    volume = {4},
    journal = {JCSE},
    HIDDEN_doi = {10.5626/JCSE.2010.4.3.207}
}

@inproceedings{Nystad12ACT,
    author = {Nystad, J. and Lassen, A. and Pomianowski, A. and Ellis, S. and Olson, T.},
    title = {Adaptive Scalable Texture Compression},
    year = {2012},
    HIDDEN_isbn = {9783905674415},
    publisher = {Eurographics Association},
    HIDDEN_address = {Goslar, DEU},
    booktitle = {Proceedings of the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics},
    HIDDEN_pages = {105-114},
    HIDDEN_numpages = {10},
    HIDDEN_location = {Paris, France},
    HIDDEN_series = {EGGH-HPG'12}
}


@article{Krajcevski16GST,
  author = {Krajcevski, Pavel and Pratapa, Srihari and Manocha, Dinesh},
  title = {{GST}: {GPU}-Decodable Supercompressed Textures},
  year = {2016},
  issue_date = {November 2016},
  publisher = {Association for Computing Machinery},
  HIDDEN_address = {New York, NY, USA},
  volume = {35},
  number = {6},
  HIDDEN_issn = {0730-0301},
  HIDDEN_url = {https://doi.org/10.1145/2980179.2982439},
  HIDDEN_doi = {10.1145/2980179.2982439},
  journal = {ACM Trans. Graph.},
  HIDDEN_month = nov,
  HIDDEN_articleno = {230},
  HIDDEN_numpages = {10},
}

@inproceedings{Noordsij20PVR,
  author = {Noordsij, Lennart and Vlugt, Steven and Bamakhrama, Mohamed and Al-Ars, Zaid and Lindstrom, Peter},
  year = {2020},
  month = {03},
  HIDDEN_pages = {},
  title = {Parallelization of Variable Rate Decompression through Metadata},
  HIDDEN_doi = {10.1109/PDP50117.2020.00045}
}

@inproceedings {Stroeam08FPB,
  booktitle = {Graphics Hardware},
  title = {Floating-Point Buffer Compression in a Unified Codec Architecture},
  author = {Ström, Jacob and Wennersten, Per and Rasmusson, Jim and Hasselgren, Jon and Munkberg, Jacob and Clarberg, Petrik and Akenine-Möller, Tomas},
  year = {2008},
}

@inproceedings{Pool12LCV,
    author = {Pool, Jeff and Lastra, Anselmo and Singh, Montek},
    title = {Lossless Compression of Variable-Precision Floating-Point Buffers on GPUs},
    year = {2012},
    HIDDEN_isbn = {9781450311946},
    publisher = {Association for Computing Machinery},
    HIDDEN_address = {New York, NY, USA},
    HIDDEN_url = {https://doi.org/10.1145/2159616.2159624},
    HIDDEN_doi = {10.1145/2159616.2159624},
    booktitle = {Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
    HIDDEN_pages = {47-54},
    HIDDEN_numpages = {8},
    HIDDEN_keywords = {compression, floating-point, variable precision},
    HIDDEN_location = {Costa Mesa, California},    
}

@article{Hasselgren06EDB,
    author = {Hasselgren, Jon and Akenine-Möller, Tomas},
    year = {2006},
    month = {09},
    HIDDEN_pages = {},
    title = {Efficient Depth Buffer Compression},
    HIDDEN_doi = {10.1145/1283900.1283917}
}
  
@article{Seiler20CPD,
    author = {Seiler, Larry and Lin, Daqi and Yuksel, Cem},
    title = {Compacted CPU/GPU Data Compression via Modified Virtual Address Translation},
    year = {2020},
    issue_date = {August 2020},
    publisher = {Association for Computing Machinery},
    HIDDEN_address = {New York, NY, USA},
    volume = {3},
    number = {2},
    HIDDEN_url = {https://doi.org/10.1145/3406177},
    HIDDEN_doi = {10.1145/3406177},
    month = aug,
    HIDDEN_articleno = {19},
    HIDDEN_numpages = {18},
    HIDDEN_keywords = {sparse textures, address swizzling, page tables, tiled resources, Shared virtual memory, lossless compression}
}


@ARTICLE{Lloyd82LSQ,
  author={Lloyd, Stuart P.},
  journal={IEEE Transactions on Information Theory}, 
  title={Least squares quantization in PCM}, 
  year={1982},
  volume={28},
  number={2},
  HIDDEN_pages={129-137},
  HIDDEN_doi={10.1109/TIT.1982.1056489}}
}

@article{Isenburg05LCP,
author = {Isenburg, Martin and Lindstrom, Peter and Snoeyink, Jack},
year = {2005},
month = {07},
pages = {869-877},
title = {Lossless compression of predicted floating-point geometry},
volume = {37},
journal = {Computer-Aided Design},
HIDDEN_doi = {10.1016/j.cad.2004.09.015}
}

@INPROCEEDINGS{Duda2015UAN,
  author={J. {Duda} and K. {Tahboub} and N. J. {Gadgil} and E. J. {Delp}},
  booktitle={2015 Picture Coding Symposium (PCS)}, 
  title={The use of asymmetric numeral systems as an accurate replacement for Huffman coding}, 
  year={2015},
  volume={},
  number={},
  pages={65-69},
}

@article{Sander07FTR,
author = {Sander, Pedro V. and Nehab, Diego and Barczak, Joshua},
title = {Fast Triangle Reordering for Vertex Locality and Reduced Overdraw},
year = {2007},
issue_date = {July 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {3},
issn = {0730-0301},
HIDDEN_url = {https://doi.org/10.1145/1276377.1276489},
HIDDEN_doi = {10.1145/1276377.1276489},
journal = {ACM Trans. Graph.},
month = jul,
pages = {89–es},
numpages = {10}
}

@article{Maggiordomo23MMC,
author = {Maggiordomo, Andrea and Moreton, Henry and Tarini, Marco},
title = {Micro-Mesh Construction},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
HIDDEN_url = {https://doi.org/10.1145/3592440},
HIDDEN_doi = {10.1145/3592440},
journal = {ACM Trans. Graph.},
articleno = {121},
numpages = {18},
keywords = {remeshing, mesh simplification, micro-meshes, displacement mapping, mesh compression}
}

@inproceedings {Kuth21VBA,
booktitle = {High-Performance Graphics - Symposium Papers},
editor = {Binder, Nikolaus and Ritschel, Tobias},
title = {Vertex-Blend Attribute Compression},
author = {Kuth, Bastian and Meyer, Quirin},
year = {2021},
publisher = {The Eurographics Association},
HIDDEN_ISSN = {2079-8687},
HIDDEN_ISBN = {978-3-03868-156-4},
HIDDEN_DOI = {10.2312/hpg.20211282}
}

@article{Peters22PCV,
author = {Peters, Christoph and Kuth, Bastian and Meyer, Quirin},
title = {Permutation Coding for Vertex-Blend Attribute Compression},
year = {2022},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
HIDDEN_url = {https://doi.org/10.1145/3522607},
HIDDEN_doi = {10.1145/3522607},
journal = {Proc. ACM Comput. Graph. Interact. Tech.},
month = {may},
articleno = {5},
numpages = {16},
keywords = {permutation coding, vertex buffer compression, tetrahedron, bone weights, simplex, bone indices, linear vertex blend animation, skinning, vertex blend attribute compression}
}

@inproceedings{Deering95GC,
    author = {Deering, Michael},
    title = {Geometry Compression},
    year = {1995},
    HIDDEN_isbn = {0897917014},
    HIDDEN_publisher = {Association for Computing Machinery},
    HIDDEN_address = {New York, NY, USA},
    HIDDEN_url = {https://doi.org/10.1145/218380.218391},
    HIDDEN_doi = {10.1145/218380.218391},
    HIDDEN_booktitle = {Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques},
    HIDDEN_pages = {13–20},
    HIDDEN_numpages = {8},
    series = {SIGGRAPH '95}
}


@manual{Callow22KFF,
author        = {Callow, Mark},
organization  = {The Khronos Group Inc.},
title         = {KTX File Format Specification v2.0.1},
year          = {2022}
}  

@inbook{Calver2002VDS,
  author    = {Calver, Dean},
  title     = {Vertex and Pixel Shader Tips and Tricks},
  chapter   = {Vertex Decompression in a Shader},
  publisher = {Wordware Publishing},
  year      = {2002},
  pages     = {172 - 187}
}

@inproceedings{Limper13PBR,
  title={{The pop buffer: Rapid progressive clustering by geometry quantization}},
  author={Limper, Max and Jung, Yvonne and Behr, Johannes and Alexa, Marc},
  booktitle={Computer Graphics Forum},
  volume={32},
  number={7},
  pages={197--206},
  year={2013},
  organization={Wiley Online Library}
}

@article{Rossignac99ECC,
  title={Edgebreaker: Connectivity compression for triangle meshes},
  author={Rossignac, Jarek},
  journal={IEEE transactions on visualization and computer graphics},
  volume={5},
  number={1},
  pages={47--61},
  year={1999},
  publisher={IEEE}
}

@ARTICLE{Delp79ICB,
  author={Delp, Edward J. and Mitchell, Owen Robert},
  journal={IEEE Transactions on Communications}, 
  title={Image Compression Using Block Truncation Coding}, 
  year={1979},
  volume={27},
  number={9},
  HIDDEN_pages={1335-1342},
  HIDDEN_doi={10.1109/TCOM.1979.1094560}
}

@phdthesis{Meyer12RTG,
author = {Meyer, Quirin},
year = {2012},
month = {08},
pages = {},
title = {Real-Time Geometry Decompression on Graphics Hardware}
}

@software{NVComp23,
 author = {Nvidia},
 title = {{nvCOMP}},
 url = "https://github.com/NVIDIA/nvcomp",    
 year =  {2023}
}

@software{BrotliG23,
  author = {{AMD}},
  title = {{Brotli-G SDK}},
  url = "https://github.com/GPUOpen-LibrariesAndSDKs/brotli_g_sdk",
  year = {2022}
}

@software{Nvidia23MM,
  author = {{Nvidia}},
  title = {{Displacement-MicroMap-Toolkit}},
  url = "https://github.com/NVIDIAGameWorks/Displacement-MicroMap-Toolkit",
  year = {2022}
}


@inproceedings{Schaefer12MAT,
author = {Sch\"{a}fer, Henry and Prus, Magdalena and Meyer, Quirin and S\"{u}\ss{}muth, Jochen and Stamminger, Marc},
title = {Multiresolution Attributes for Tessellated Meshes},
year = {2012},
HIDDEN_isbn = {9781450311946},
publisher = {Association for Computing Machinery},
HIDDEN_address = {New York, NY, USA},
HIDDEN_url = {https://doi.org/10.1145/2159616.2159645},
HIDDEN_doi = {10.1145/2159616.2159645},
booktitle = {Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
HIDDEN_pages = {175–182},
HIDDEN_numpages = {8},
HIDDEN_keywords = {tessellation, displacement mapping, signal dependent storage},
HIDDEN_location = {Costa Mesa, California},
HIDDEN_series = {I3D '12}
}

@inproceedings{Meyer10OFN,
    author = {Meyer, Quirin and S\"{u}\ss{}muth, Jochen and Su\ss{}ner, Gerd and Stamminger, Marc and Greiner, G\"{u}nther},
    title = {On Floating-Point Normal Vectors},
    year = {2010},
    publisher = {Eurographics Association},
    HIDDEN_address = {Goslar, DEU},
    HIDDEN_url = {https://doi.org/10.1111/j.1467-8659.2010.01737.x},
    HIDDEN_doi = {10.1111/j.1467-8659.2010.01737.x},
    booktitle = {Proceedings of the 21st Eurographics Conference on Rendering},
    HIDDEN_pages = {1405-1409},
    HIDDEN_numpages = {5},
    HIDDEN_location = {Saarbr\"{u}cken, Germany},
    series = {EGSR'10}
}

@article{Mlakar24EEC,
author = {Mlakar, D. and Steinberger, M. and Schmalstieg, D.},
title = {End-to-End Compressed Meshlet Rendering},
journal = {Computer Graphics Forum},
volume = {43},
number = {1},
HIDDEN_pages = {e15002},
HIDDEN_keywords = {modeling, compression algorithms},
HIDDEN_doi = {https://doi.org/10.1111/cgf.15002},
HIDDEN_url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.15002},
HIDDEN_eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.15002},
year = {2024}
}

@article{Gurung11LRC,
author = {Gurung, Topraj and Luffel, Mark and Lindstrom, Peter and Rossignac, Jarek},
title = {LR: compact connectivity representation for triangle meshes},
year = {2011},
HIDDEN_issue_date = {July 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
HIDDEN_issn = {0730-0301},
HIDDEN_url = {https://doi.org/10.1145/2010324.1964962},
HIDDEN_doi = {10.1145/2010324.1964962},
journal = {ACM Trans. Graph.},
HIDDEN_month = {jul},
HIDDEN_articleno = {67},
HIDDEN_numpages = {8},

}

@inproceedings{sivaram2024patchnets,
	address = {Denver CO USA},
	title = {Neural {Geometry} {Fields} {For} {Meshes}},
	isbn = {979-8-4007-0525-0},
	url = {https://dl.acm.org/doi/10.1145/3641519.3657399},
	doi = {10.1145/3641519.3657399},
	abstract = {Recent work on using neural fields to represent surfaces has resulted in significant improvements in representational capability and computational efficiency. However, to our knowledge, most existing work has focused on implicit representations such as signed distance fields or volumes, and little work has explored their application to discrete surface geometry, i.e., 3D meshes, limiting the applicability of neural surface representations.},
	language = {en},
	urldate = {2025-04-12},
	booktitle = {Special {Interest} {Group} on {Computer} {Graphics} and {Interactive} {Techniques} {Conference} {Conference} {Papers} '24},
	publisher = {ACM},
	author = {Sivaram, Venkataram and Li, Tzu-Mao and Ramamoorthi, Ravi},
	month = jul,
	year = {2024},
	pages = {1--11},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\F3DGMDZS\\Edavamadathil Sivaram et al. - 2024 - Neural Geometry Fields For Meshes.pdf:application/pdf},
}

@misc{pentapati_mesh_2025,
	title = {Mesh {Compression} with {Quantized} {Neural} {Displacement} {Fields}},
	url = {http://arxiv.org/abs/2504.01027},
	doi = {10.48550/arXiv.2504.01027},
	abstract = {Implicit neural representations (INRs) have been successfully used to compress a variety of 3D surface representations such as Signed Distance Functions (SDFs), voxel grids, and also other forms of structured data such as images, videos, and audio. However, these methods have been limited in their application to unstructured data such as 3D meshes and point clouds. This work presents a simple yet effective method that extends the usage of INRs to compress 3D triangle meshes. Our method encodes a displacement field that refines the coarse version of the 3D mesh surface to be compressed using a small neural network. Once trained, the neural network weights occupy much lower memory than the displacement field or the original surface. We show that our method is capable of preserving intricate geometric textures and demonstrates state-of-the-art performance for compression ratios ranging from 4x to 380x (See Figure 1 for an example).},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Pentapati, Sai Karthikey and Phillips, Gregoire and Bovik, Alan C.},
	month = mar,
	year = {2025},
	note = {arXiv:2504.01027 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\5QX5VJ7T\\Pentapati et al. - 2025 - Mesh Compression with Quantized Neural Displacement Fields.pdf:application/pdf},
}

@misc{ren_necgs_2024,
	title = {{NeCGS}: {Neural} {Compression} for {3D} {Geometry} {Sets}},
	shorttitle = {{NeCGS}},
	url = {http://arxiv.org/abs/2405.15034},
	doi = {10.48550/arXiv.2405.15034},
	abstract = {We present NeCGS, the first neural compression paradigm, which can compress a geometry set encompassing thousands of detailed and diverse 3D mesh models by up to 900 times with high accuracy and preservation of detailed geometric structures. Specifically, we first propose TSDF-Def, a new implicit representation that is capable of accurately representing irregular 3D mesh models with various structures into regular 4D tensors of uniform and compact size, where 3D surfaces can be extracted through the deformable marching cubes. Then we construct a quantization-aware auto-decoder network architecture to regress these 4D tensors to explore the local geometric similarity within each shape and across different shapes for redundancy removal, resulting in more compact representations, including an embedded feature of a smaller size associated with each 3D model and a network parameter shared by all models. We finally encode the resulting features and network parameters into bitstreams through entropy coding. Besides, our NeCGS can handle the dynamic scenario well, where new 3D models are constantly added to a compressed set. Extensive experiments and ablation studies demonstrate the significant advantages of our NeCGS over state-of-the-art methods both quantitatively and qualitatively. The source code is available at https://github.com/rsy6318/NeCGS.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Ren, Siyu and Hou, Junhui and Wang, Wenping},
	month = nov,
	year = {2024},
	note = {arXiv:2405.15034 [cs]},
	keywords = {Computer Science - Computational Geometry},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\8VA9KPYZ\\Ren et al. - 2024 - NeCGS Neural Compression for 3D Geometry Sets.pdf:application/pdf},
}

@misc{postels_3d_2023,
	title = {{3D} {Compression} {Using} {Neural} {Fields}},
	url = {http://arxiv.org/abs/2311.13009},
	doi = {10.48550/arXiv.2311.13009},
	abstract = {Neural Fields (NFs) have gained momentum as a tool for compressing various data modalities - e.g. images and videos. This work leverages previous advances and proposes a novel NF-based compression algorithm for 3D data. We derive two versions of our approach - one tailored to watertight shapes based on Signed Distance Fields (SDFs) and, more generally, one for arbitrary nonwatertight shapes using Unsigned Distance Fields (UDFs). We demonstrate that our method excels at geometry compression on 3D point clouds as well as meshes. Moreover, we show that, due to the NF formulation, it is straightforward to extend our compression algorithm to compress both geometry and attribute (e.g. color) of 3D data.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Postels, Janis and Strümpler, Yannick and Reichard, Klara and Gool, Luc Van and Tombari, Federico},
	month = nov,
	year = {2023},
	note = {arXiv:2311.13009 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\I3GFWILF\\Postels et al. - 2023 - 3D Compression Using Neural Fields.pdf:application/pdf},
}

@inproceedings{yang_geometry_2023,
	address = {Sydney NSW Australia},
	title = {Geometry {Processing} with {Neural} {Fields}},
	isbn = {979-8-4007-0392-8},
	url = {https://dl.acm.org/doi/10.1145/3623053.3623365},
	doi = {10.1145/3623053.3623365},
	abstract = {Most existing geometry processing algorithms use meshes as the default shape representation. Manipulating meshes, however, requires one to maintain high quality in the surface discretization. For example, changing the topology of a mesh usually requires additional procedures such as remeshing. This paper instead proposes the use of neural fields for geometry processing. Neural fields can compactly store complicated shapes without spatial discretization. Moreover, neural fields are infinitely differentiable, which allows them to be optimized for objectives that involve higher-order derivatives. This raises the question: can geometry processing be done entirely using neural fields? We introduce loss functions and architectures to show that some of the most challenging geometry processing tasks, such as deformation and filtering, can be done with neural fields. Experimental results show that our methods are on par with the well-established mesh-based methods without committing to a particular surface discretization. Code is available at https://github.com/stevenygd/NFGP.},
	language = {en},
	urldate = {2025-04-12},
	booktitle = {{SIGGRAPH} {Asia} 2023 {Doctoral} {Consortium}},
	publisher = {ACM},
	author = {Yang, Guandao and Belongie, Serge and Hariharan, Bharath and Koltun, Vladlen},
	month = nov,
	year = {2023},
	pages = {1--5},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\ZP5FSC9Y\\Yang - 2023 - Geometry Processing with Neural Fields.pdf:application/pdf},
}

@misc{xie_neural_2022,
	title = {Neural {Fields} in {Visual} {Computing} and {Beyond}},
	url = {http://arxiv.org/abs/2111.11426},
	doi = {10.48550/arXiv.2111.11426},
	abstract = {Recent advances in machine learning have led to increased interest in solving visual computing problems using methods that employ coordinate-based neural networks. These methods, which we call neural ﬁelds, parameterize physical properties of scenes or objects across space and time. They have seen widespread success in problems such as 3D shape and image synthesis, animation of human bodies, 3D reconstruction, and pose estimation. Rapid progress has led to numerous papers, but a consolidation of the discovered knowledge has not yet emerged. We provide context, mathematical grounding, and a review of over 250 papers in the literature on neural ﬁelds. In Part I, we focus on neural ﬁeld techniques by identifying common components of neural ﬁeld methods, including different conditioning, representation, forward map, architecture, and manipulation methods. In Part II, we focus on applications of neural ﬁelds to different problems in visual computing, and beyond (e.g., robotics, audio). Our review shows the breadth of topics already covered in visual computing, both historically and in current incarnations, and highlights the improved quality, ﬂexibility, and capability brought by neural ﬁeld methods. Finally, we present a companion website that acts as a living database that can be continually updated by the community.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Xie, Yiheng and Takikawa, Towaki and Saito, Shunsuke and Litany, Or and Yan, Shiqin and Khan, Numair and Tombari, Federico and Tompkin, James and Sitzmann, Vincent and Sridhar, Srinath},
	month = apr,
	year = {2022},
	note = {arXiv:2111.11426 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	annote = {Comment: Equal advising: Vincent Sitzmann and Srinath Sridhar},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\92HEGTC9\\Xie et al. - 2022 - Neural Fields in Visual Computing and Beyond.pdf:application/pdf},
}

@misc{chen_neural_2023,
	title = {Neural {Progressive} {Meshes}},
	url = {http://arxiv.org/abs/2308.05741},
	doi = {10.48550/arXiv.2308.05741},
	abstract = {The recent proliferation of 3D content that can be consumed on hand-held devices necessitates efficient tools for transmitting large geometric data, e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a challenge to storage as well as transmission bandwidth, and level-of-detail techniques are often used to transmit an asset using an appropriate bandwidth budget. It is especially desirable for these methods to transmit data progressively, improving the quality of the geometry with more data. Our key insight is that the geometric details of 3D meshes often exhibit similar local patterns even across different shapes, and thus can be effectively represented with a shared learned generative space. We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces. We further observe that additional residual features can be transmitted progressively between intermediate levels of subdivision that enable the client to control the tradeoff between bandwidth cost and quality of reconstruction, providing a neural progressive mesh representation. We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Chen, Yun-Chun and Kim, Vladimir G. and Aigerman, Noam and Jacobson, Alec},
	month = aug,
	year = {2023},
	note = {arXiv:2308.05741 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	annote = {Comment: SIGGRAPH 2023},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\NQRIKWYQ\\Chen et al. - 2023 - Neural Progressive Meshes.pdf:application/pdf},
}

@article{lescoat_spectral_2020,
	title = {Spectral {Mesh} {Simplification}},
	volume = {39},
	issn = {0167-7055, 1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13932},
	doi = {10.1111/cgf.13932},
	abstract = {The spectrum of the Laplace-Beltrami operator is instrumental for a number of geometric modeling applications, from processing to analysis. Recently, multiple methods were developed to retrieve an approximation of a shape that preserves its eigenvectors as much as possible, but these techniques output a subset of input points with no connectivity, which limits their potential applications. Furthermore, the obtained Laplacian results from an optimization procedure, implying its storage alongside the selected points. Focusing on keeping a mesh instead of an operator would allow to retrieve the latter using the standard cotangent formulation, enabling easier processing afterwards. Instead, we propose to simplify the input mesh using a spectrum-preserving mesh decimation scheme, so that the Laplacian computed on the simpliﬁed mesh is spectrally close to the one of the input mesh. We illustrate the beneﬁt of our approach for quickly approximating spectral distances and functional maps on low resolution proxies of potentially high resolution input meshes.},
	language = {en},
	number = {2},
	urldate = {2025-04-12},
	journal = {Computer Graphics Forum},
	author = {Lescoat, Thibault and Liu, Hsueh‐Ti Derek and Thiery, Jean‐Marc and Jacobson, Alec and Boubekeur, Tamy and Ovsjanikov, Maks},
	month = may,
	year = {2020},
	pages = {315--324},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\ELW6MYWZ\\Lescoat et al. - 2020 - Spectral Mesh Simplification.pdf:application/pdf},
}

@article{Maglo2015,
	title = {{3D} {Mesh} {Compression}: {Survey}, {Comparisons}, and {Emerging} {Trends}},
	volume = {47},
	issn = {0360-0300, 1557-7341},
	shorttitle = {{3D} {Mesh} {Compression}},
	url = {https://dl.acm.org/doi/10.1145/2693443},
	doi = {10.1145/2693443},
	abstract = {3D meshes are commonly used to represent virtual surface and volumes. However, their raw data representations take a large amount of space. Hence, 3D mesh compression has been an active research topic since the mid 1990s. In 2005, two very good review articles describing the pioneering works were published. Yet, new technologies have emerged since then. In this article, we summarize the early works and put the focus on these novel approaches. We classify and describe the algorithms, evaluate their performance, and provide synthetic comparisons. We also outline the emerging trends for future research.},
	language = {en},
	number = {3},
	urldate = {2025-04-12},
	journal = {ACM Computing Surveys},
	author = {Maglo, Adrien and Lavoué, Guillaume and Dupont, Florent and Hudelot, Céline},
	month = apr,
	year = {2015},
	pages = {1--41},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\VVEBNHUN\\Maglo et al. - 2015 - 3D Mesh Compression Survey, Comparisons, and Emerging Trends.pdf:application/pdf},
}

@misc{wang_neus_2023,
	title = {{NeuS}: {Learning} {Neural} {Implicit} {Surfaces} by {Volume} {Rendering} for {Multi}-view {Reconstruction}},
	shorttitle = {{NeuS}},
	url = {http://arxiv.org/abs/2106.10689},
	doi = {10.48550/arXiv.2106.10689},
	abstract = {We present a novel neural surface reconstruction method, called NeuS, for reconstructing objects and scenes with high ﬁdelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR [Niemeyer et al., 2020] and IDR [Yariv et al., 2020], require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures. Meanwhile, recent neural methods for novel view synthesis, such as NeRF [Mildenhall et al., 2020] and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difﬁcult because there are not sufﬁcient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a signed distance function (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the ﬁrst order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Wang, Peng and Liu, Lingjie and Liu, Yuan and Theobalt, Christian and Komura, Taku and Wang, Wenping},
	month = feb,
	year = {2023},
	note = {arXiv:2106.10689 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	annote = {Comment: 23 pages},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\K2RQMSK2\\Wang et al. - 2023 - NeuS Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction.pdf:application/pdf},
}

@misc{mescheder2019occupancy,
	title = {Occupancy {Networks}: {Learning} {3D} {Reconstruction} in {Function} {Space}},
	shorttitle = {Occupancy {Networks}},
	url = {http://arxiv.org/abs/1812.03828},
	doi = {10.48550/arXiv.1812.03828},
	abstract = {With the advent of deep neural networks, learning-based approaches for 3D reconstruction have gained popularity. However, unlike for images, in 3D there is no canonical representation which is both computationally and memory efﬁcient yet allows for representing high-resolution geometry of arbitrary topology. Many of the state-of-the-art learningbased 3D reconstruction approaches can hence only represent very coarse 3D geometry or are limited to a restricted domain. In this paper, we propose Occupancy Networks, a new representation for learning-based 3D reconstruction methods. Occupancy networks implicitly represent the 3D surface as the continuous decision boundary of a deep neural network classiﬁer. In contrast to existing approaches, our representation encodes a description of the 3D output at inﬁnite resolution without excessive memory footprint. We validate that our representation can efﬁciently encode 3D structure and can be inferred from various kinds of input. Our experiments demonstrate competitive results, both qualitatively and quantitatively, for the challenging tasks of 3D reconstruction from single images, noisy point clouds and coarse discrete voxel grids. We believe that occupancy networks will become a useful tool in a wide variety of learning-based 3D tasks.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
	month = apr,
	year = {2019},
	note = {arXiv:1812.03828 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: To be presented at CVPR 2019. Supplementary material and code is available at http://avg.is.tuebingen.mpg.de/publications/occupancy-networks},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\A7SIWPH9\\Mescheder et al. - 2019 - Occupancy Networks Learning 3D Reconstruction in Function Space.pdf:application/pdf},
}

@misc{Park2019,
	title = {{DeepSDF}: {Learning} {Continuous} {Signed} {Distance} {Functions} for {Shape} {Representation}},
	shorttitle = {{DeepSDF}},
	url = {http://arxiv.org/abs/1901.05103},
	doi = {10.48550/arXiv.1901.05103},
	abstract = {Computer graphics, 3D computer vision and robotics communities have produced multiple approaches to representing 3D geometry for rendering and reconstruction. These provide trade-offs across ﬁdelity, efﬁciency and compression capabilities. In this work, we introduce DeepSDF, a learned continuous Signed Distance Function (SDF) representation of a class of shapes that enables high quality shape representation, interpolation and completion from partial and noisy 3D input data. DeepSDF, like its classical counterpart, represents a shape’s surface by a continuous volumetric ﬁeld: the magnitude of a point in the ﬁeld represents the distance to the surface boundary and the sign indicates whether the region is inside (-) or outside (+) of the shape, hence our representation implicitly encodes a shape’s boundary as the zero-level-set of the learned function while explicitly representing the classiﬁcation of space as being part of the shapes interior or not. While classical SDF’s both in analytical or discretized voxel form typically represent the surface of a single shape, DeepSDF can represent an entire class of shapes. Furthermore, we show stateof-the-art performance for learned 3D shape representation and completion while reducing the model size by an order of magnitude compared with previous work.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
	month = jan,
	year = {2019},
	note = {arXiv:1901.05103 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\C7XEHNSK\\Park et al. - 2019 - DeepSDF Learning Continuous Signed Distance Functions for Shape Representation.pdf:application/pdf},
}

@misc{pentapati_mesh_2025,
	title = {Mesh {Compression} with {Quantized} {Neural} {Displacement} {Fields}},
	url = {http://arxiv.org/abs/2504.01027},
	doi = {10.48550/arXiv.2504.01027},
	abstract = {Implicit neural representations (INRs) have been successfully used to compress a variety of 3D surface representations such as Signed Distance Functions (SDFs), voxel grids, and also other forms of structured data such as images, videos, and audio. However, these methods have been limited in their application to unstructured data such as 3D meshes and point clouds. This work presents a simple yet effective method that extends the usage of INRs to compress 3D triangle meshes. Our method encodes a displacement field that refines the coarse version of the 3D mesh surface to be compressed using a small neural network. Once trained, the neural network weights occupy much lower memory than the displacement field or the original surface. We show that our method is capable of preserving intricate geometric textures and demonstrates state-of-the-art performance for compression ratios ranging from 4x to 380x (See Figure 1 for an example).},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Pentapati, Sai Karthikey and Phillips, Gregoire and Bovik, Alan C.},
	month = mar,
	year = {2025},
	note = {arXiv:2504.01027 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\5QX5VJ7T\\Pentapati et al. - 2025 - Mesh Compression with Quantized Neural Displacement Fields.pdf:application/pdf},
}

@misc{ren_necgs_2024,
	title = {{NeCGS}: {Neural} {Compression} for {3D} {Geometry} {Sets}},
	shorttitle = {{NeCGS}},
	url = {http://arxiv.org/abs/2405.15034},
	doi = {10.48550/arXiv.2405.15034},
	abstract = {We present NeCGS, the first neural compression paradigm, which can compress a geometry set encompassing thousands of detailed and diverse 3D mesh models by up to 900 times with high accuracy and preservation of detailed geometric structures. Specifically, we first propose TSDF-Def, a new implicit representation that is capable of accurately representing irregular 3D mesh models with various structures into regular 4D tensors of uniform and compact size, where 3D surfaces can be extracted through the deformable marching cubes. Then we construct a quantization-aware auto-decoder network architecture to regress these 4D tensors to explore the local geometric similarity within each shape and across different shapes for redundancy removal, resulting in more compact representations, including an embedded feature of a smaller size associated with each 3D model and a network parameter shared by all models. We finally encode the resulting features and network parameters into bitstreams through entropy coding. Besides, our NeCGS can handle the dynamic scenario well, where new 3D models are constantly added to a compressed set. Extensive experiments and ablation studies demonstrate the significant advantages of our NeCGS over state-of-the-art methods both quantitatively and qualitatively. The source code is available at https://github.com/rsy6318/NeCGS.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Ren, Siyu and Hou, Junhui and Wang, Wenping},
	month = nov,
	year = {2024},
	note = {arXiv:2405.15034 [cs]},
	keywords = {Computer Science - Computational Geometry},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\8VA9KPYZ\\Ren et al. - 2024 - NeCGS Neural Compression for 3D Geometry Sets.pdf:application/pdf},
}

@misc{postels_3d_2023,
	title = {{3D} {Compression} {Using} {Neural} {Fields}},
	url = {http://arxiv.org/abs/2311.13009},
	doi = {10.48550/arXiv.2311.13009},
	abstract = {Neural Fields (NFs) have gained momentum as a tool for compressing various data modalities - e.g. images and videos. This work leverages previous advances and proposes a novel NF-based compression algorithm for 3D data. We derive two versions of our approach - one tailored to watertight shapes based on Signed Distance Fields (SDFs) and, more generally, one for arbitrary nonwatertight shapes using Unsigned Distance Fields (UDFs). We demonstrate that our method excels at geometry compression on 3D point clouds as well as meshes. Moreover, we show that, due to the NF formulation, it is straightforward to extend our compression algorithm to compress both geometry and attribute (e.g. color) of 3D data.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Postels, Janis and Strümpler, Yannick and Reichard, Klara and Gool, Luc Van and Tombari, Federico},
	month = nov,
	year = {2023},
	note = {arXiv:2311.13009 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\I3GFWILF\\Postels et al. - 2023 - 3D Compression Using Neural Fields.pdf:application/pdf},
}

@inproceedings{yang_geometry_2023,
	address = {Sydney NSW Australia},
	title = {Geometry {Processing} with {Neural} {Fields}},
	isbn = {979-8-4007-0392-8},
	url = {https://dl.acm.org/doi/10.1145/3623053.3623365},
	doi = {10.1145/3623053.3623365},
	abstract = {Most existing geometry processing algorithms use meshes as the default shape representation. Manipulating meshes, however, requires one to maintain high quality in the surface discretization. For example, changing the topology of a mesh usually requires additional procedures such as remeshing. This paper instead proposes the use of neural fields for geometry processing. Neural fields can compactly store complicated shapes without spatial discretization. Moreover, neural fields are infinitely differentiable, which allows them to be optimized for objectives that involve higher-order derivatives. This raises the question: can geometry processing be done entirely using neural fields? We introduce loss functions and architectures to show that some of the most challenging geometry processing tasks, such as deformation and filtering, can be done with neural fields. Experimental results show that our methods are on par with the well-established mesh-based methods without committing to a particular surface discretization. Code is available at https://github.com/stevenygd/NFGP.},
	language = {en},
	urldate = {2025-04-12},
	booktitle = {{SIGGRAPH} {Asia} 2023 {Doctoral} {Consortium}},
	publisher = {ACM},
	author = {Yang, Guandao and Belongie, Serge and Hariharan, Bharath and Koltun, Vladlen},
	month = nov,
	year = {2023},
	pages = {1--5},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\ZP5FSC9Y\\Yang - 2023 - Geometry Processing with Neural Fields.pdf:application/pdf},
}

@misc{xie_neural_2022,
	title = {Neural {Fields} in {Visual} {Computing} and {Beyond}},
	url = {http://arxiv.org/abs/2111.11426},
	doi = {10.48550/arXiv.2111.11426},
	abstract = {Recent advances in machine learning have led to increased interest in solving visual computing problems using methods that employ coordinate-based neural networks. These methods, which we call neural ﬁelds, parameterize physical properties of scenes or objects across space and time. They have seen widespread success in problems such as 3D shape and image synthesis, animation of human bodies, 3D reconstruction, and pose estimation. Rapid progress has led to numerous papers, but a consolidation of the discovered knowledge has not yet emerged. We provide context, mathematical grounding, and a review of over 250 papers in the literature on neural ﬁelds. In Part I, we focus on neural ﬁeld techniques by identifying common components of neural ﬁeld methods, including different conditioning, representation, forward map, architecture, and manipulation methods. In Part II, we focus on applications of neural ﬁelds to different problems in visual computing, and beyond (e.g., robotics, audio). Our review shows the breadth of topics already covered in visual computing, both historically and in current incarnations, and highlights the improved quality, ﬂexibility, and capability brought by neural ﬁeld methods. Finally, we present a companion website that acts as a living database that can be continually updated by the community.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Xie, Yiheng and Takikawa, Towaki and Saito, Shunsuke and Litany, Or and Yan, Shiqin and Khan, Numair and Tombari, Federico and Tompkin, James and Sitzmann, Vincent and Sridhar, Srinath},
	month = apr,
	year = {2022},
	note = {arXiv:2111.11426 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	annote = {Comment: Equal advising: Vincent Sitzmann and Srinath Sridhar},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\92HEGTC9\\Xie et al. - 2022 - Neural Fields in Visual Computing and Beyond.pdf:application/pdf},
}

@misc{chen_neural_2023,
	title = {Neural {Progressive} {Meshes}},
	url = {http://arxiv.org/abs/2308.05741},
	doi = {10.48550/arXiv.2308.05741},
	abstract = {The recent proliferation of 3D content that can be consumed on hand-held devices necessitates efficient tools for transmitting large geometric data, e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a challenge to storage as well as transmission bandwidth, and level-of-detail techniques are often used to transmit an asset using an appropriate bandwidth budget. It is especially desirable for these methods to transmit data progressively, improving the quality of the geometry with more data. Our key insight is that the geometric details of 3D meshes often exhibit similar local patterns even across different shapes, and thus can be effectively represented with a shared learned generative space. We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces. We further observe that additional residual features can be transmitted progressively between intermediate levels of subdivision that enable the client to control the tradeoff between bandwidth cost and quality of reconstruction, providing a neural progressive mesh representation. We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Chen, Yun-Chun and Kim, Vladimir G. and Aigerman, Noam and Jacobson, Alec},
	month = aug,
	year = {2023},
	note = {arXiv:2308.05741 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	annote = {Comment: SIGGRAPH 2023},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\NQRIKWYQ\\Chen et al. - 2023 - Neural Progressive Meshes.pdf:application/pdf},
}

@article{lescoat_spectral_2020,
	title = {Spectral {Mesh} {Simplification}},
	volume = {39},
	issn = {0167-7055, 1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13932},
	doi = {10.1111/cgf.13932},
	abstract = {The spectrum of the Laplace-Beltrami operator is instrumental for a number of geometric modeling applications, from processing to analysis. Recently, multiple methods were developed to retrieve an approximation of a shape that preserves its eigenvectors as much as possible, but these techniques output a subset of input points with no connectivity, which limits their potential applications. Furthermore, the obtained Laplacian results from an optimization procedure, implying its storage alongside the selected points. Focusing on keeping a mesh instead of an operator would allow to retrieve the latter using the standard cotangent formulation, enabling easier processing afterwards. Instead, we propose to simplify the input mesh using a spectrum-preserving mesh decimation scheme, so that the Laplacian computed on the simpliﬁed mesh is spectrally close to the one of the input mesh. We illustrate the beneﬁt of our approach for quickly approximating spectral distances and functional maps on low resolution proxies of potentially high resolution input meshes.},
	language = {en},
	number = {2},
	urldate = {2025-04-12},
	journal = {Computer Graphics Forum},
	author = {Lescoat, Thibault and Liu, Hsueh‐Ti Derek and Thiery, Jean‐Marc and Jacobson, Alec and Boubekeur, Tamy and Ovsjanikov, Maks},
	month = may,
	year = {2020},
	pages = {315--324},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\ELW6MYWZ\\Lescoat et al. - 2020 - Spectral Mesh Simplification.pdf:application/pdf},
}

@article{maglo_3d_2015,
	title = {{3D} {Mesh} {Compression}: {Survey}, {Comparisons}, and {Emerging} {Trends}},
	volume = {47},
	issn = {0360-0300, 1557-7341},
	shorttitle = {{3D} {Mesh} {Compression}},
	url = {https://dl.acm.org/doi/10.1145/2693443},
	doi = {10.1145/2693443},
	abstract = {3D meshes are commonly used to represent virtual surface and volumes. However, their raw data representations take a large amount of space. Hence, 3D mesh compression has been an active research topic since the mid 1990s. In 2005, two very good review articles describing the pioneering works were published. Yet, new technologies have emerged since then. In this article, we summarize the early works and put the focus on these novel approaches. We classify and describe the algorithms, evaluate their performance, and provide synthetic comparisons. We also outline the emerging trends for future research.},
	language = {en},
	number = {3},
	urldate = {2025-04-12},
	journal = {ACM Computing Surveys},
	author = {Maglo, Adrien and Lavoué, Guillaume and Dupont, Florent and Hudelot, Céline},
	month = apr,
	year = {2015},
	pages = {1--41},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\VVEBNHUN\\Maglo et al. - 2015 - 3D Mesh Compression Survey, Comparisons, and Emerging Trends.pdf:application/pdf},
}

@misc{wang_neus_2023,
	title = {{NeuS}: {Learning} {Neural} {Implicit} {Surfaces} by {Volume} {Rendering} for {Multi}-view {Reconstruction}},
	shorttitle = {{NeuS}},
	url = {http://arxiv.org/abs/2106.10689},
	doi = {10.48550/arXiv.2106.10689},
	abstract = {We present a novel neural surface reconstruction method, called NeuS, for reconstructing objects and scenes with high ﬁdelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR [Niemeyer et al., 2020] and IDR [Yariv et al., 2020], require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures. Meanwhile, recent neural methods for novel view synthesis, such as NeRF [Mildenhall et al., 2020] and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difﬁcult because there are not sufﬁcient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a signed distance function (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the ﬁrst order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion.},
	language = {en},
	urldate = {2025-04-12},
	publisher = {arXiv},
	author = {Wang, Peng and Liu, Lingjie and Liu, Yuan and Theobalt, Christian and Komura, Taku and Wang, Wenping},
	month = feb,
	year = {2023},
	note = {arXiv:2106.10689 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	annote = {Comment: 23 pages},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\K2RQMSK2\\Wang et al. - 2023 - NeuS Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction.pdf:application/pdf},
}

@misc{tretschk_patchnets_2021,
	title = {{PatchNets}: {Patch}-{Based} {Generalizable} {Deep} {Implicit} {3D} {Shape} {Representations}},
	shorttitle = {{PatchNets}},
	url = {http://arxiv.org/abs/2008.01639},
	doi = {10.48550/arXiv.2008.01639},
	abstract = {Implicit surface representations, such as signed-distance functions, combined with deep learning have led to impressive models which can represent detailed shapes of objects with arbitrary topology. Since a continuous function is learned, the reconstructions can also be extracted at any arbitrary resolution. However, large datasets such as ShapeNet are required to train such models.},
	language = {en},
	urldate = {2025-04-27},
	publisher = {arXiv},
	author = {Tretschk, Edgar and Tewari, Ayush and Golyanik, Vladislav and Zollhöfer, Michael and Stoll, Carsten and Theobalt, Christian},
	month = feb,
	year = {2021},
	note = {arXiv:2008.01639 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	annote = {Comment: 25 pages, including supplementary material. Code: https://github.com/edgar-tr/patchnets Project page: https://gvv.mpi-inf.mpg.de/projects/PatchNets/},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\99AUY8JH\\Tretschk et al. - 2021 - PatchNets Patch-Based Generalizable Deep Implicit 3D Shape Representations.pdf:application/pdf},
}

@article{garland1997surface,
	title = {Surface simplification using quadric error metrics},
	abstract = {Many applications in computer graphics require complex, highly detailed models. However, the level of detail actually necessary may vary considerably. To control processing time, it is often desirable to use approximations in place of excessively detailed models. We have developed a surface simpliﬁcation algorithm which can rapidly produce high quality approximations of polygonal models. The algorithm uses iterative contractions of vertex pairs to simplify models and maintains surface error approximations using quadric matrices. By contracting arbitrary vertex pairs (not just edges), our algorithm is able to join unconnected regions of models. This can facilitate much better approximations, both visually and with respect to geometric error. In order to allow topological joining, our system also supports non-manifold surface models.},
	language = {en},
	author = {Garland, Michael and Heckbert, Paul S},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\PYIEGYVS\\Garland und Heckbert - Surface simplification using quadric error metrics.pdf:application/pdf},
}

@article{bernardini1999ball,
	title = {The ball-pivoting algorithm for surface reconstruction},
	volume = {5},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/817351/},
	doi = {10.1109/2945.817351},
	abstract = {The Ball-Pivoting Algorithm (BPA) computes a triangle mesh interpolating a given point cloud. Typically, the points are surface samples acquired with multiple range scans of an object. The principle of the BPA is very simple: Three points form a triangle if a ball of a user-specified radius touches them without containing any other point. Starting with a seed triangle, the ball pivots around an edge (i.e., it revolves around the edge while keeping in contact with the edge's endpoints) until it touches another point, forming another triangle. The process continues until all reachable edges have been tried, and then starts from another seed triangle, until all points have been considered. The process can then be repeated with a ball of larger radius to handle uneven sampling densities. We applied the BPA to datasets of millions of points representing actual scans of complex 3D objects. The relatively small amount of memory required by the BPA, its time efficiency, and the quality of the results obtained compare favorably with existing techniques.},
	language = {en},
	number = {4},
	urldate = {2025-04-27},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bernardini, F. and Mittleman, J. and Rushmeier, H. and Silva, C. and Taubin, G.},
	month = oct,
	year = {1999},
	pages = {349--359},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\QSZPIIHH\\Bernardini et al. - 1999 - The ball-pivoting algorithm for surface reconstruction.pdf:application/pdf},
}

@article{kazhdan2006poisson,
	title = {Poisson {Surface} {Reconstruction}},
	abstract = {We show that surface reconstruction from oriented points can be cast as a spatial Poisson problem. This Poisson formulation considers all the points at once, without resorting to heuristic spatial partitioning or blending, and is therefore highly resilient to data noise. Unlike radial basis function schemes, our Poisson approach allows a hierarchy of locally supported basis functions, and therefore the solution reduces to a well conditioned sparse linear system. We describe a spatially adaptive multiscale algorithm whose time and space complexities are proportional to the size of the reconstructed model. Experimenting with publicly available scan data, we demonstrate reconstruction of surfaces with greater detail than previously achievable.},
	language = {en},
	author = {Kazhdan, Michael and Bolitho, Matthew and Hoppe, Hugues},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\RC49CFDK\\Kazhdan et al. - Poisson Surface Reconstruction.pdf:application/pdf},
}

@article{lorensen1987marching,
	title = {Marching cubes: {A} high resolution {3D} surface construction algorithm},
	abstract = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
	language = {en},
	author = {Lorensen, William E and Cline, Harvey E},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\84EXNDAG\\Lorensen und Cline - Marching cubes A high resolution 3D surface construction algorithm.pdf:application/pdf},
}

@article{sitzmann2020implicit,
	title = {Implicit {Neural} {Representations} with {Periodic} {Activation} {Functions}},
	abstract = {Implicitly deﬁned, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible beneﬁts over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with ﬁne detail. They also fail to accurately model spatial and temporal derivatives, which is necessary to represent signals deﬁned implicitly by differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or SIRENs, are ideally suited for representing complex natural signals and their derivatives. We analyze SIREN activation statistics to propose a principled initialization scheme and demonstrate the representation of images, waveﬁelds, video, sound, three-dimensional shapes, and their derivatives. Further, we show how SIRENs can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine SIRENs with hypernetworks to learn priors over the space of SIREN functions. Please see the project website for a video overview of the proposed method and all applications.},
	language = {en},
	author = {Sitzmann, Vincent and Martel, Julien N P and Bergman, Alexander W and Lindell, David B and Wetzstein, Gordon},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\KNAJSK86\\Sitzmann et al. - Implicit Neural Representations with Periodic Activation Functions.pdf:application/pdf},
}

@inproceedings{groueix2018atlasnet,
	address = {Salt Lake City, UT, USA},
	title = {A {Papier}-{Mache} {Approach} to {Learning} {3D} {Surface} {Generation}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578128/},
	doi = {10.1109/CVPR.2018.00030},
	abstract = {We introduce a method for learning to generate the surface of 3D shapes. Our approach represents a 3D shape as a collection of parametric surface elements and, in contrast to methods generating voxel grids or point clouds, naturally infers a surface representation of the shape. Beyond its novelty, our new shape generation framework, AtlasNet, comes with signiﬁcant advantages, such as improved precision and generalization capabilities, and the possibility to generate a shape of arbitrary resolution without memory issues. We demonstrate these beneﬁts and compare to strong baselines on the ShapeNet benchmark for two applications: (i) autoencoding shapes, and (ii) single-view reconstruction from a still image. We also provide results showing its potential for other applications, such as morphing, parametrization, super-resolution, matching, and co-segmentation.},
	language = {en},
	urldate = {2025-04-27},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Groueix, Thibault and Fisher, Matthew and Kim, Vladimir G. and Russell, Bryan C. and Aubry, Mathieu},
	month = jun,
	year = {2018},
	pages = {216--224},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\VPUC9L3S\\Groueix et al. - 2018 - A Papier-Mache Approach to Learning 3D Surface Generation.pdf:application/pdf},
}

@misc{sajnani2020draco,
	title = {{DRACO}: {Weakly} {Supervised} {Dense} {Reconstruction} {And} {Canonicalization} of {Objects}},
	shorttitle = {{DRACO}},
	url = {http://arxiv.org/abs/2011.12912},
	doi = {10.48550/arXiv.2011.12912},
	abstract = {We present DRACO, a method for Dense Reconstruction And Canonicalization of Object shape from one or more RGB images. Canonical shape reconstruction—estimating 3D object shape in a coordinate space canonicalized for scale, rotation, and translation parameters—is an emerging paradigm that holds promise for a multitude of robotic applications. Prior approaches either rely on painstakingly gathered dense 3D supervision, or produce only sparse canonical representations, limiting real-world applicability. DRACO performs dense canonicalization using only weak supervision in the form of camera poses and semantic keypoints at train time. During inference, DRACO predicts dense object-centric depth maps in a canonical coordinate-space, solely using one or more RGB images of an object. Extensive experiments on canonical shape reconstruction and pose estimation show that DRACO is competitive or superior to fully-supervised methods.},
	language = {en},
	urldate = {2025-04-27},
	publisher = {arXiv},
	author = {Sajnani, Rahul and Sanchawala, AadilMehdi and Jatavallabhula, Krishna Murthy and Sridhar, Srinath and Krishna, K. Madhava},
	month = nov,
	year = {2020},
	note = {arXiv:2011.12912 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	annote = {Comment: Preprint. For project page and code, see https://aadilmehdis.github.io/DRACO-Project-Page/},
	file = {PDF:C\:\\Users\\Dinge\\Zotero\\storage\\YMVJJF2U\\Sajnani et al. - 2020 - DRACO Weakly Supervised Dense Reconstruction And Canonicalization of Objects.pdf:application/pdf},
}
