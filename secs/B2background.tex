\section{Previous Work}\label{sec:PreviousWork}

The domain of 3D geometry representation has undergone substantial evolution, driven by the ongoing need to balance precision, computational efficiency and representational flexibility.  
In the following, we review the principal categories of related work that establish the foundation for Neural Geometry Fields, encompassing traditional mesh-based techniques, neural implicit representations and recent hybrid approaches.  

\subsection{Traditional Mesh-Based Techniques}

Meshes have historically constituted the main format for representing 3D geometries within computer graphics.  
Their vertex-based structure enables explicit control over topology and surface detail.  
However, the dense nature of mesh data often leads to significant memory consumption and computational overhead.  

To minimize these limitations, a range of mesh simplification and compression methods have been introduced.  
An important tool in this area is QSlim~\cite{garland1997}, which utilizes quadric error metrics to systematically reduce mesh complexity while striving to preserve essential geometric features.  
In the field of data compression, techniques such as Draco~\cite{sajnani2020} exploit spatial coherence and vertex connectivity to achieve substantial reductions in storage requirements, particularly targeting web-based scenarios.  
Nevertheless, these approaches typically entail a trade-off between geometric details and compactness, a compromise that becomes especially important in high-resolution or dynamically changing datasets.  

In addition, surface reconstruction methods, such as Poisson Surface Reconstruction~\cite{kazhdan2006} and the Ball-Pivoting Algorithm~\cite{bernardini1999}, have been widely employed to recover continuous surfaces from unstructured point clouds.  
While effective under controlled conditions, these algorithms are often sensitive to input noise, require meticulous parameter tuning and inherently produce triangle meshes with fixed topological properties, limiting their adaptability to complex or highly detailed shapes.  

\subsection{Neural Implicit Representations}

Recent advances in deep learning have led to the development of neural implicit representations, offering an alternative paradigm to traditional discrete models.  
Rather than explicitly storing mesh connectivity or surface elements, these approaches encode 3D geometry as continuous functions, typically signed distance fields or occupancy probability fields, which are parameterized by neural networks.  

A pioneering contribution to neural implicit representations is DeepSDF.  
DeepSDF introduces the concept of learning a continuous shape space, where each distinct 3D object is associated with a compact latent vector.  
This latent vector, when passed through a neural network decoder, defines a Signed Distance Function.  
This function maps any point in 3D space to a scalar value representing the shortest distance to the object's surface, with the sign indicating whether the point lies inside or outside the surface boundary.  
By optimizing both the latent codes and the shared network parameters jointly, DeepSDF achieves efficient representation of complex geometric structures while maintaining compactness.  
This formulation allows smooth interpolation between shapes in the learned latent space and facilitates high-fidelity surface reconstruction through iso-surface extraction~\cite{park2019}.  

In parallel, Occupancy Networks propose a related but distinct approach.  
Rather than predicting signed distances, Occupancy Networks model the occupancy probability of each point in 3D space.  
Which means, the likelihood that a given point resides inside the object's volume.  
This occupancy function is parameterized by a Multi-Layer Perceptron, a type of fully connected neural network that maps 3D coordinates (and optionally conditional information, such as a latent code) directly to scalar occupancy values between 0 and 1.  
This continuous probabilistic formulation enables the generation of smooth, high-resolution surfaces without committing to a fixed spatial discretization such as voxels~\cite{mescheder2019}.  

These implicit methods offer several significant advantages.  
Their continuity and resolution-independence make them particularly well-suited for tasks such as shape interpolation, morphing and differentiable rendering.  
However, as the geometric information is inherently implicit, explicit surface representations must typically be extracted through iso-surface extraction algorithms such as Marching Cubes~\cite{lorensen1987}.  
This post-processing introduces discretization artifacts, impacts real-time performance and often struggles to faithfully capture fine-grained structural details or guarantee topological consistency~\cite{sitzmann2020}.  

\subsection{Hybrid Approaches and Emerging Techniques}

Recognizing the strengths and limitations of explicit and implicit representations, recent research efforts have increasingly focused on hybrid approaches that integrate neural modeling with structured surface representations.  

For instance, Neural Subdivision ~\cite{liu2020} and AtlasNet~\cite{groueix2018} reconstruct 3D geometry using collections of learnable patches or parametric mappings, offering enhanced control over both local surface details and global topology.  
Building on these ideas, patch-based methods such as PatchNets~\cite{sivaram2024} have been proposed, wherein structured surface primitives, such as quadrilateral patches, are directly predicted from latent neural features.  
Such approaches aim to alleviate the inefficiencies associated with iso-surface extraction and to produce structured, differentiable representations more directly.