Neural Geometry Fields (NGFs) represent a hybrid approach that unifies mesh-based structure with neural implicit flexibility to achieve compact, high-fidelity 3D reconstructions.  
NGFs partition surfaces into local patches, each encoded by a lightweight feature field and decoded via shared Multilayer Perceptron (MLP).  
This enables real-time mesh extraction (under 1 s per object) and achieves a 2x lower Chamfer distance compared to state-of-the-art baselines.  
The integration of differentiable inverse rendering jointly supervises geometry and appearance, ensuring scalability to high-resolution scenes without prohibitive memory overhead.  
Quantitative benchmarks and qualitative visualizations demonstrate that NGFs deliver superior detail preservation and real-time performance.  
This approach addresses the question of how to integrate mesh structure and neural flexibility for compact, accurate 3D reconstructions.  
